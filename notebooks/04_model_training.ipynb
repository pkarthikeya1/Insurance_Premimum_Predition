{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\karthikeya\\\\Insurance_Premium_Prediction'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import joblib as jl\n",
    "from src.logger import logger\n",
    "\n",
    "from src.utils import evaluate_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelTrainerConfig:\n",
    "    trained_model_file_path = os.path.join(\"artifacts\", \"model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model_trainer_config = ModelTrainerConfig()\n",
    "\n",
    "    def initiate_model_training(self, train_array, test_array):\n",
    "        try:\n",
    "            logger.info(\"splitting train and test input data\")\n",
    "\n",
    "            X_train,y_train, X_test, y_test = (\n",
    "                train_array[:, :-1],\n",
    "                train_array[:, -1],\n",
    "                test_array[:, :-1],\n",
    "                test_array[:, -1]\n",
    "            )\n",
    "\n",
    "            models = {\n",
    "                \"RandomForest\":RandomForestRegressor(),\n",
    "                \"DecisionTree\": DecisionTreeRegressor(),\n",
    "                \"GradientBoosting\" : GradientBoostingRegressor(),\n",
    "                \"LinearRegression\" : LinearRegression(),\n",
    "                \"XGBRegressor\" : XGBRegressor(),\n",
    "                \"AdaBoostRegressor\": AdaBoostRegressor()\n",
    "\n",
    "            }\n",
    "            model_report:dict = evaluate_models(\n",
    "                X_train=X_train,\n",
    "                y_train=y_train,\n",
    "                X_test= X_test,\n",
    "                y_test =y_test,\n",
    "                models= models)\n",
    "            \n",
    "            best_model_score = max(sorted(model_report.values()))\n",
    "\n",
    "            best_model_name = list(model_report.keys())[\n",
    "                list(model_report.values()).index(best_model_score)\n",
    "            ]\n",
    "\n",
    "            best_model = models[best_model_name]\n",
    "\n",
    "            if best_model_score<0.6:\n",
    "                raise Exception(\"No best model found\")\n",
    "            \n",
    "            logger.info(f\"Best found model on both training and testing dataset\")\n",
    "\n",
    "            model_obj = jl.dump(best_model,self.model_trainer_config.trained_model_file_path)\n",
    "\n",
    "            predicted = best_model.predict(X_test)\n",
    "\n",
    "            R2_score = r2_score(y_test, predicted)\n",
    "\n",
    "            return R2_score\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.components.data_ingestion import DataIngestion, DataIngestionConfig\n",
    "from src.components.data_transformation import DataTransformation, DataTransformationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-19 19:38:37,742, INFO, data_ingestion, Entered the data ingestion method ]\n",
      "[2024-11-19 19:38:37,743, INFO, data_ingestion, Establishing Connection with SQLite databse ]\n",
      "[2024-11-19 19:38:37,745, INFO, utils, Successfully connected to the SQLite database. ]\n",
      "[2024-11-19 19:38:42,483, INFO, data_ingestion, Successfuly read the raw data as dataframe ]\n",
      "[2024-11-19 19:38:42,485, INFO, utils, Disconnected from the SQLite database. ]\n",
      "[2024-11-19 19:38:42,485, INFO, data_ingestion, Disconnected from SQLite database ]\n",
      "[2024-11-19 19:38:42,486, INFO, data_ingestion, Train Test Split Initiated ]\n",
      "[2024-11-19 19:38:53,373, INFO, data_ingestion, Data ingestion is complete ]\n",
      "[2024-11-19 19:38:56,017, INFO, data_transformation, Reading train and test data completed ]\n",
      "[2024-11-19 19:38:56,018, INFO, data_transformation, Obtaining preprocessing object ]\n",
      "[2024-11-19 19:38:56,018, INFO, data_transformation, Numerical columns standard scaling completed ]\n",
      "[2024-11-19 19:38:56,019, INFO, data_transformation, Categorical columns encoding completed ]\n",
      "[2024-11-19 19:38:56,022, INFO, data_transformation, saved preprocessor as joblib file in the path artifacts\\preprocessor.joblib ]\n",
      "[2024-11-19 19:38:56,023, INFO, data_transformation, Applying preprocessor on train dataset and test dataset ]\n",
      "[2024-11-19 19:38:59,556, INFO, 1419277232, splitting train and test input data ]\n",
      "[2024-11-19 19:54:51,399, INFO, 1419277232, Best found model on both training and testing dataset ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8245757070520024"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = DataIngestion()\n",
    "_, train_data, test_data = obj.initiate_data_ingestion()\n",
    "\n",
    "data_transformation = DataTransformation()\n",
    "\n",
    "train_arr, test_arr,_ = data_transformation.initiate_data_transformation(train_data, test_data)\n",
    "\n",
    "model_trainer = ModelTrainer()\n",
    "\n",
    "model_trainer.initiate_model_training(train_arr, test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
